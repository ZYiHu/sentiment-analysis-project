import os
import json
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

# è®¾ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰è„šæœ¬ï¼‰
MODEL_DIR = os.path.join("models", "sentiment")

# æ·»åŠ è‡ªå®šä¹‰åŠ è½½å‡½æ•°
def load_model_with_compatibility(model_path):
    """è§£å†³PyTorch 2.6+å…¼å®¹æ€§é—®é¢˜"""
    from transformers import DistilBertForSequenceClassification
    
    # åŠ è½½é…ç½®
    config = AutoConfig.from_pretrained(model_path)
    
    # åˆ›å»ºç©ºæ¨¡å‹
    model = DistilBertForSequenceClassification(config)
    
    # æ‰‹åŠ¨åŠ è½½æƒé‡
    state_dict = torch.load(
        os.path.join(model_path, "pytorch_model.bin"),
        map_location="cpu",
        weights_only=False  # å…³é”®è®¾ç½®
    )
    
    # åŠ è½½æƒé‡
    model.load_state_dict(state_dict)
    
    return model


def create_compatible_pipeline():
    """åˆ›å»ºå…¼å®¹çš„Pipeline"""
    from transformers import DistilBertForSequenceClassification, DistilBertTokenizer
    import torch
    
    # æ‰‹åŠ¨åŠ è½½ç»„ä»¶
    tokenizer = DistilBertTokenizer.from_pretrained(MODEL_DIR)
    model = DistilBertForSequenceClassification.from_pretrained(
        MODEL_DIR,
        state_dict=torch.load(
            os.path.join(MODEL_DIR, "pytorch_model.bin"),
            map_location="cpu",
            weights_only=False  # å…³é”®è®¾ç½®
        )
    )
    
    # åˆ›å»ºè‡ªå®šä¹‰Pipeline
    from transformers import pipeline
    return pipeline(
        "sentiment-analysis",
        model=model,
        tokenizer=tokenizer
    )

def check_model_files():
    """æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("=" * 60)
    print("æ­£åœ¨æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    print("=" * 60)
    
    required_files = [
        ("config.json", "æ¨¡å‹é…ç½®æ–‡ä»¶"),
        ("pytorch_model.bin", "æ¨¡å‹æƒé‡æ–‡ä»¶"),
        ("vocab.txt", "è¯æ±‡è¡¨æ–‡ä»¶"),
        ("tokenizer_config.json", "åˆ†è¯å™¨é…ç½®æ–‡ä»¶")
    ]
    
    all_files_present = True
    
    for file_name, description in required_files:
        file_path = os.path.join(MODEL_DIR, file_name)
        exists = os.path.exists(file_path)
        status = "âœ“ å­˜åœ¨" if exists else "âœ— ç¼ºå¤±"
        print(f"{status} | {file_name:25} | {description}")
        
        if not exists:
            all_files_present = False
    
    print("=" * 60)
    
    if all_files_present:
        print("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²å°±ç»ªï¼")
        return True
    else:
        print("âŒ ç¼ºå°‘å¿…éœ€æ–‡ä»¶ï¼Œè¯·ä¸‹è½½ç¼ºå¤±æ–‡ä»¶åå†è¿è¡Œ")
        print(f"ä¸‹è½½åœ°å€: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/tree/main")
        return False
    
    json_files = ["config.json", "tokenizer_config.json"]
    for file in json_files:
        path = os.path.join(MODEL_DIR, file)
        try:
            with open(path, 'r') as f:
                json.load(f)
            print(f"âœ“ JSONæ ¼å¼éªŒè¯é€šè¿‡: {file}")
        except Exception as e:
            print(f"âŒ JSONæ ¼å¼é”™è¯¯: {file} - {str(e)}")
            all_files_present = False

def analyze_with_pipeline():
    """ä½¿ç”¨Pipelineè¿›è¡Œæƒ…æ„Ÿåˆ†æ"""
    print("\n" + "=" * 60)
    print("ä½¿ç”¨æ–¹æ³•1: Transformers Pipeline")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæƒ…æ„Ÿåˆ†æpipeline
        classifier = pipeline(
            "sentiment-analysis",
            model=MODEL_DIR,  # ç›´æ¥æŒ‡å®šæ¨¡å‹ç›®å½•
            tokenizer=MODEL_DIR  # ç›´æ¥æŒ‡å®šåˆ†è¯å™¨ç›®å½•
        )
        
        # åˆ†ææ–‡æœ¬
        texts = [
            "I love using Transformers!",
            "This product is terrible.",
            "The weather is nice today.",
            "I'm frustrated with this issue."
        ]
        
        for text in texts:
            result = classifier(text)
            label = result[0]['label']
            score = result[0]['score']
            
            # æ·»åŠ è¡¨æƒ…ç¬¦å·å¢å¼ºå¯è¯»æ€§
            emoji = "ğŸ˜Š" if label == "POSITIVE" else "ğŸ˜"
            print(f"{emoji} æ–‡æœ¬: '{text}'")
            print(f"   æƒ…æ„Ÿ: {label} (ç½®ä¿¡åº¦: {score:.4f})")
            print("-" * 50)
            
        print("âœ… Pipeline åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ Pipeline å‡ºé”™: {str(e)}")

def analyze_manually():
    """æ‰‹åŠ¨åŠ è½½æ¨¡å‹è¿›è¡Œåˆ†æ"""
    print("\n" + "=" * 60)
    print("ä½¿ç”¨æ–¹æ³•2: æ‰‹åŠ¨åŠ è½½æ¨¡å‹")
    print("=" * 60)
    
    try:
        try:
            import safetensors
            import safetensors.torch
        except ImportError:
            print("å®‰è£… safetensors...")
            import subprocess
            subprocess.check_call(["pip", "install", "safetensors"])
            import safetensors
            import safetensors.torch

        # åŠ è½½åˆ†è¯å™¨
        tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
        
        # åŠ è½½æ¨¡å‹
        model = load_safetensors_model(MODEL_DIR)
        
        # è¦åˆ†æçš„æ–‡æœ¬
        text = "Manual loading works perfectly!"
        
        # é¢„å¤„ç†æ–‡æœ¬
        inputs = tokenizer(text, return_tensors="pt")
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            outputs = model(**inputs)
        
        # è·å–é¢„æµ‹ç»“æœ
        logits = outputs.logits
        probabilities = torch.nn.functional.softmax(logits, dim=1)
        predicted_class = torch.argmax(probabilities).item()
        sentiment = "POSITIVE" if predicted_class == 1 else "NEGATIVE"
        confidence = probabilities[0][predicted_class].item()
        
        # æ·»åŠ è¡¨æƒ…ç¬¦å·
        emoji = "ğŸ˜Š" if sentiment == "POSITIVE" else "ğŸ˜"
        
        print(f"{emoji} æ–‡æœ¬: '{text}'")
        print(f"   æƒ…æ„Ÿ: {sentiment} (ç½®ä¿¡åº¦: {confidence:.4f})")
        print(f"   åŸå§‹logits: {logits.tolist()}")
        print(f"   æ¦‚ç‡åˆ†å¸ƒ: {probabilities.tolist()}")
        print("âœ… æ‰‹åŠ¨åŠ è½½åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ‰‹åŠ¨åŠ è½½å‡ºé”™: {str(e)}")

# æ·»åŠ  safetensors åŠ è½½å‡½æ•°
def load_safetensors_model(model_path):
    """ä½¿ç”¨ safetensors åŠ è½½æ¨¡å‹"""
    from transformers import AutoConfig, DistilBertForSequenceClassification
    import safetensors.torch
    
    # åŠ è½½é…ç½®
    config = AutoConfig.from_pretrained(model_path)
    
    # åˆ›å»ºç©ºæ¨¡å‹
    model = DistilBertForSequenceClassification(config)
    
    # åŠ è½½ safetensors æ–‡ä»¶
    state_dict = safetensors.torch.load_file(
        os.path.join(model_path, "model.safetensors"),
        device="cpu"
    )
    
    # åŠ è½½æƒé‡
    model.load_state_dict(state_dict)
    
    return model

if __name__ == "__main__":
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if check_model_files():
        # è¿è¡Œä¸¤ç§åˆ†ææ–¹æ³•
        analyze_with_pipeline()
        analyze_manually()
        
        print("\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")
        print("æ‚¨å¯ä»¥åœ¨ models/sentiment/ ç›®å½•æŸ¥çœ‹æ¨¡å‹æ–‡ä»¶")
        print("ä¸‹æ¬¡è¿è¡Œæ— éœ€é‡æ–°ä¸‹è½½æ¨¡å‹")
    else:
        print("\nè¯·ä¸‹è½½ç¼ºå¤±æ–‡ä»¶åé‡æ–°è¿è¡Œç¨‹åº")